{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VcK27MSd4C8O"
      },
      "outputs": [],
      "source": [
        "# 1. 安装依赖\n",
        "!pip install ftfy regex tqdm\n",
        "!pip install git+https://github.com/openai/CLIP.git\n",
        "\n",
        "import os\n",
        "import torch\n",
        "from PIL import Image\n",
        "import torchvision.transforms as T\n",
        "from urllib import request\n",
        "\n",
        "# 2. 下载自定义模型权重和词表（如果你上传到 GitHub，替换下面链接）\n",
        "model_url = \"https://github.com/JoyBingzhi/clip-image-text-matching/raw/main/clip-imp-pretrained_128_6_after_4.pt\"\n",
        "vocab_url = \"https://github.com/JoyBingzhi/clip-image-text-matching/raw/main/bpe_simple_vocab_16e6.txt.gz\"\n",
        "dog_url = \"https://github.com/JoyBingzhi/clip-image-text-matching/raw/main/test_images/dog.jpg\"\n",
        "plane_url = \"https://github.com/JoyBingzhi/clip-image-text-matching/raw/main/test_images/airplane.jpg\"\n",
        "\n",
        "os.makedirs(\"model\", exist_ok=True)\n",
        "if not os.path.exists(\"model/clip-imp-pretrained_128_6_after_4.pt\"):\n",
        "    request.urlretrieve(model_url, \"model/clip-imp-pretrained_128_6_after_4.pt\")\n",
        "if not os.path.exists(\"model/bpe_simple_vocab_16e6.txt.gz\"):\n",
        "    request.urlretrieve(vocab_url, \"model/bpe_simple_vocab_16e6.txt.gz\")\n",
        "if not os.path.exists(\"dog.jpg\"):\n",
        "    request.urlretrieve(dog_url, \"dog.jpg\")\n",
        "if not os.path.exists(\"airplane.jpg\"):\n",
        "    request.urlretrieve(plane_url, \"airplane.jpg\")\n",
        "\n",
        "# 3. 导入自定义模块\n",
        "import sys\n",
        "sys.path.append(\"./\")  # 确保能找到 custom_clip.py 和 custom_tokenizer.py\n",
        "\n",
        "from custom_clip import load\n",
        "from custom_tokenizer import SimpleTokenizer\n",
        "\n",
        "# 4. 加载模型\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model, _ = load(name=\"ViT-B/32\", device=device, jit=False)\n",
        "\n",
        "# 加载预训练权重\n",
        "state_dict = torch.load(\"model/clip-imp-pretrained_128_6_after_4.pt\", map_location=device)\n",
        "model.load_state_dict(state_dict)\n",
        "model.eval()\n",
        "\n",
        "# 5. 图像预处理\n",
        "preprocess = T.Compose([\n",
        "    T.Resize(224, interpolation=Image.BICUBIC),\n",
        "    T.CenterCrop(224),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=[0.48145466, 0.4578275, 0.40821073],\n",
        "                std=[0.26862954, 0.26130258, 0.27577711]),\n",
        "])\n",
        "\n",
        "images = []\n",
        "for path in [\"dog.jpg\", \"airplane.jpg\"]:\n",
        "    img = Image.open(path).convert(\"RGB\")\n",
        "    images.append(preprocess(img).unsqueeze(0))\n",
        "images = torch.cat(images).to(device)\n",
        "\n",
        "# 6. 文本处理\n",
        "texts = [\"This is a dog.\", \"This is an airplane.\"]\n",
        "tokenizer = SimpleTokenizer()\n",
        "tokenized = [tokenizer.encode(t) for t in texts]\n",
        "max_len = max(len(t) for t in tokenized)\n",
        "\n",
        "text_tensor = torch.zeros(len(texts), max_len, dtype=torch.long).to(device)\n",
        "for i, tokens in enumerate(tokenized):\n",
        "    text_tensor[i, :len(tokens)] = torch.tensor(tokens)\n",
        "\n",
        "# 7. 提取特征\n",
        "with torch.no_grad():\n",
        "    image_features = model.encode_image(images)\n",
        "    text_features = model.encode_text(text_tensor)\n",
        "\n",
        "# 8. 计算相似度\n",
        "image_features /= image_features.norm(dim=-1, keepdim=True)\n",
        "text_features /= text_features.norm(dim=-1, keepdim=True)\n",
        "\n",
        "similarity = (100.0 * image_features @ text_features.T)\n",
        "\n",
        "# 9. 输出结果\n",
        "for i, path in enumerate([\"dog.jpg\", \"airplane.jpg\"]):\n",
        "    print(f\"Image: {path}\")\n",
        "    for j, text in enumerate(texts):\n",
        "        print(f\"  '{text}': {similarity[i][j].item():.2f}\")\n"
      ]
    }
  ]
}