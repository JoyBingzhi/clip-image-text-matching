{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install ftfy regex tqdm\n",
        "import os\n",
        "import torch\n",
        "from PIL import Image\n",
        "import torchvision.transforms as T\n",
        "from urllib import request"
      ],
      "metadata": {
        "id": "pSfkSiNj3TK7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_url = \"https://github.com/JoyBingzhi/clip-image-text-matching/raw/main/bpe_simple_vocab_16e6.txt.gz\"\n",
        "dog_url = \"https://github.com/JoyBingzhi/clip-image-text-matching/raw/main/test_images/dog.jpg\"\n",
        "plane_url = \"https://github.com/JoyBingzhi/clip-image-text-matching/raw/main/test_images/airplane.jpg\"\n",
        "clip_url = \"https://github.com/JoyBingzhi/clip-image-text-matching/raw/main/custom_clip.py\"\n",
        "model_url = \"https://github.com/JoyBingzhi/clip-image-text-matching/raw/main/custom_model.py\"\n",
        "tokenizer_url = \"https://github.com/JoyBingzhi/clip-image-text-matching/raw/main/custom_tokenizer.py\"\n"
      ],
      "metadata": {
        "id": "Sx37L1EArb_U"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "request.urlretrieve(vocab_url, \"bpe_simple_vocab_16e6.txt.gz\")\n",
        "request.urlretrieve(clip_url, \"custom_clip.py\")\n",
        "request.urlretrieve(model_url, \"custom_model.py\")\n",
        "request.urlretrieve(tokenizer_url, \"custom_tokenizer.py\")\n",
        "from custom_clip import load\n",
        "from custom_tokenizer import SimpleTokenizer"
      ],
      "metadata": {
        "id": "x8icuSYcvHP6"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 4. 加载模型\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model, _ = load(name=\"ViT-B/32\", device=device, jit=False)\n",
        "\n",
        "# 加载预训练权重\n",
        "state_dict = torch.load(\"clip-imp-pretrained_128_6_after_4.pt\", map_location=device)\n",
        "model.load_state_dict(state_dict)\n",
        "model.eval()\n",
        "\n",
        "# 5. 图像预处理\n",
        "preprocess = T.Compose([\n",
        "    T.Resize(224, interpolation=Image.BICUBIC),\n",
        "    T.CenterCrop(224),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=[0.48145466, 0.4578275, 0.40821073],\n",
        "                std=[0.26862954, 0.26130258, 0.27577711]),\n",
        "])\n",
        "\n",
        "images = []\n",
        "for path in [\"dog.jpg\", \"airplane.jpg\"]:\n",
        "    img = Image.open(path).convert(\"RGB\")\n",
        "    images.append(preprocess(img).unsqueeze(0))\n",
        "images = torch.cat(images).to(device)\n",
        "\n",
        "# 6. 文本处理\n",
        "texts = [\"This is a dog.\", \"This is an airplane.\"]\n",
        "tokenizer = SimpleTokenizer()\n",
        "tokenized = [tokenizer.encode(t) for t in texts]\n",
        "# max_len = max(len(t) for t in tokenized)\n",
        "max_len = 77\n",
        "text_tensor = torch.zeros(len(texts), max_len, dtype=torch.long).to(device)\n",
        "for i, tokens in enumerate(tokenized):\n",
        "    text_tensor[i, :len(tokens)] = torch.tensor(tokens)\n",
        "\n",
        "# 7. 提取特征\n",
        "with torch.no_grad():\n",
        "    image_features = model.encode_image(images)\n",
        "    text_features = model.encode_text(text_tensor)\n",
        "\n",
        "# 8. 计算相似度\n",
        "image_features /= image_features.norm(dim=-1, keepdim=True)\n",
        "text_features /= text_features.norm(dim=-1, keepdim=True)\n",
        "\n",
        "similarity = (100.0 * image_features @ text_features.T)\n",
        "\n",
        "# 9. 输出结果\n",
        "for i, path in enumerate([\"dog.jpg\", \"airplane.jpg\"]):\n",
        "    print(f\"Image: {path}\")\n",
        "    for j, text in enumerate(texts):\n",
        "        print(f\"  '{text}': {similarity[i][j].item():.2f}\")"
      ],
      "metadata": {
        "id": "IAhW-OpUsj7-",
        "outputId": "56c4a732-de77-46ed-caec-532833a6a5e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: dog.jpg\n",
            "  'This is a dog.': 28.22\n",
            "  'This is an airplane.': 25.43\n",
            "Image: airplane.jpg\n",
            "  'This is a dog.': 20.38\n",
            "  'This is an airplane.': 24.84\n"
          ]
        }
      ]
    }
  ]
}